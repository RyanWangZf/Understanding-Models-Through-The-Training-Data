{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import unicode_literals  \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, preprocessing, cluster\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.linalg as slin\n",
    "import scipy.sparse.linalg as sparselin\n",
    "import scipy.sparse as sparse\n",
    "import IPython\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/radaimi/Documents/influence-release-master/influence\")\n",
    "from inceptionModel import BinaryInceptionModel\n",
    "from logisticRegressionWithLBFGS import LogisticRegressionWithLBFGS\n",
    "from binaryLogisticRegressionWithLBFGS import BinaryLogisticRegressionWithLBFGS\n",
    "\n",
    "from load_animals import load_animals\n",
    "\n",
    "import experiments\n",
    "from image_utils import plot_flat_bwimage, plot_flat_bwgrad, plot_flat_colorimage, plot_flat_colorgrad\n",
    " \n",
    "from dataset import DataSet\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_preprocess(x):\n",
    "    x /= 2.\n",
    "    x += 0.5\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading animals from disk...\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "num_train_ex_per_class = 900\n",
    "num_test_ex_per_class = 300\n",
    "\n",
    "model_name = 'dogfish_%s_%s' % (num_train_ex_per_class, num_test_ex_per_class)\n",
    "image_data_sets = load_animals(\n",
    "    num_train_ex_per_class=num_train_ex_per_class, \n",
    "    num_test_ex_per_class=num_test_ex_per_class,\n",
    "    classes=['dog', 'fish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n",
      "WARNING:tensorflow:From /home/radaimi/Documents/influence-release-master/influence_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/radaimi/Documents/influence-release-master/influence_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1168: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/radaimi/Documents/influence-release-master/influence_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radaimi/Documents/influence-release-master/influence_env/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'dogfish'\n",
    "img_side = 299\n",
    "num_channels = 3\n",
    " \n",
    "batch_size = 100\n",
    "initial_learning_rate = 0.001 \n",
    "keep_probs = None\n",
    "decay_epochs = [1000, 10000]\n",
    "weight_decay = 0.001\n",
    "model_name = '%s_inception' % dataset_name\n",
    "\n",
    "num_classes = 2\n",
    "model = BinaryInceptionModel(\n",
    "    img_side=img_side,\n",
    "    num_channels=num_channels,\n",
    "    weight_decay=weight_decay,\n",
    "    num_classes=num_classes, \n",
    "    batch_size=batch_size,\n",
    "    data_sets=image_data_sets,\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    keep_probs=keep_probs,\n",
    "    decay_epochs=decay_epochs,\n",
    "    mini_batch=True,\n",
    "    train_dir='output',\n",
    "    log_dir='log',\n",
    "    model_name=dataset_name)\n",
    "\n",
    "\n",
    "image_data_sets.train.reset_batch()\n",
    "image_data_sets.test.reset_batch()\n",
    "\n",
    "\n",
    "for data_set, label in [\n",
    "    (image_data_sets.train, 'train'),\n",
    "    (image_data_sets.test, 'test')]:\n",
    "\n",
    "    data_set.reset_batch()\n",
    "\n",
    "    num_examples = data_set.num_examples\n",
    "    if num_examples > 100:\n",
    "        batch_size = 100\n",
    "    else:\n",
    "        batch_size = num_examples\n",
    "    \n",
    "    assert num_examples % batch_size == 0\n",
    "    num_iter = int(num_examples / batch_size)\n",
    "\n",
    "    inception_features_val = []\n",
    "    for i in range(num_iter):\n",
    "        feed_dict = model.fill_feed_dict_with_batch(data_set, batch_size=batch_size)\n",
    "        inception_features_val_temp = model.sess.run(model.inception_features, feed_dict=feed_dict)\n",
    "        inception_features_val.append(inception_features_val_temp)\n",
    "\n",
    "    np.savez(\n",
    "        'data/%s_features_new_%s.npz' % (model_name, label), \n",
    "        inception_features_val=np.concatenate(inception_features_val),\n",
    "        labels=data_set.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n",
      "Using normal model\n",
      "LBFGS training took [42] iter.\n",
      "After training with LBFGS: \n",
      "Train loss (w reg) on all data: 0.01212904\n",
      "Train loss (w/o reg) on all data: 0.003976129\n",
      "Test loss (w/o reg) on all data: 0.048454043\n",
      "Train acc on all data:  1.0\n",
      "Test acc on all data:   0.985\n",
      "Norm of the mean of gradients: 3.6104618e-07\n",
      "Norm of the params: 4.0380473\n"
     ]
    }
   ],
   "source": [
    "model_name = 'dogfish'\n",
    "\n",
    "train_f = np.load('/home/radaimi/Documents/influence-release-master/scripts/data/%s_inception_features_new_train.npz' % model_name)\n",
    "train = DataSet(train_f['inception_features_val'], train_f['labels'])\n",
    "test_f = np.load('/home/radaimi/Documents/influence-release-master/scripts/data/%s_inception_features_new_test.npz' % model_name)\n",
    "test = DataSet(test_f['inception_features_val'], test_f['labels'])\n",
    "validation = None\n",
    "\n",
    "data_sets = base.Datasets(train=train, validation=validation, test=test)\n",
    "\n",
    "input_dim = 2048\n",
    "weight_decay = 0.001\n",
    "batch_size = 900\n",
    "initial_learning_rate = 0.001 \n",
    "keep_probs = None\n",
    "decay_epochs = [1000, 10000]\n",
    "max_lbfgs_iter = 1000\n",
    "num_classes = 2\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "model = BinaryLogisticRegressionWithLBFGS(\n",
    "    input_dim=input_dim,\n",
    "    weight_decay=weight_decay,\n",
    "    max_lbfgs_iter=max_lbfgs_iter,\n",
    "    num_classes=num_classes, \n",
    "    batch_size=batch_size,\n",
    "    data_sets=data_sets,\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    keep_probs=keep_probs,\n",
    "    decay_epochs=decay_epochs,\n",
    "    mini_batch=False,\n",
    "    train_dir='data',\n",
    "    log_dir='log',\n",
    "    model_name='%s_inception_onlytop' % model_name)\n",
    "\n",
    "model.train()\n",
    "weights = model.sess.run(model.weights)\n",
    "np.save('data/inception_weights_%s' % model_name, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look for good test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(model.data_sets.test.labels == data_sets.test.labels)\n",
    "assert np.all(model.data_sets.train.labels == data_sets.train.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.sess.run(model.preds, feed_dict=model.all_test_feed_dict)\n",
    "Y_test = model.data_sets.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [0.29343987 0.70656013]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2048 into shape (299,299,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4ae478d1cc54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     test_idx = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/influence-release-master/influence_env/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    290\u001b[0m            [5, 6]])\n\u001b[1;32m    291\u001b[0m     \"\"\"\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/influence-release-master/influence_env/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 2048 into shape (299,299,3)"
     ]
    }
   ],
   "source": [
    "for test_idx in range(600):\n",
    "    if np.max(Y_pred[test_idx,]) > 0.999: continue\n",
    "    if Y_test[test_idx] == 0: continue\n",
    "#     test_idx = 0\n",
    "    print(test_idx, Y_pred[test_idx])\n",
    "    plt.imshow((np.reshape(image_data_sets.test.x[test_idx, :], [299, 299, 3]) + 1) / 2, interpolation='none')  \n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = [35, 161, 250, 325, 447, 573, 578]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_idx in test_indices:\n",
    "    print(test_idx, Y_pred[test_idx])\n",
    "    plt.imshow((np.reshape(image_data_sets.test.x[test_idx, :], [299, 299, 3]) + 1) / 2, interpolation='none')  \n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test indices: [35, 161, 250, 325, 447, 573, 578]\n",
    "test_idx = 161\n",
    "model_string = 'dogfish_%s_%s_inception' % (num_train_ex_per_class, num_test_ex_per_class)\n",
    "\n",
    "# train_dict = np.load('/srv/scratch/pangwei/influence_data/animals_900_300_inception_inception_features_poisoned_train_influence_poison-MAI-replace-0.1_testidx_[21].npz')\n",
    "train_dict = np.load(\n",
    "    '/srv/scratch/pangwei/influence_data/%s_inception_features_poisoned_train_influence_poison-maxgrad-linf-replace-0.01_testidx_[%s].npz'\\\n",
    "    % (model_string, test_idx))\n",
    "# train_dict = np.load('/srv/scratch/pangwei/influence_data/%s_features_train.npz' % model_string)\n",
    "### Normal\n",
    "# train_dict = np.load('data/%s_features_train.npz' % model_string)\n",
    "\n",
    "train = DataSet(np.reshape(train_dict['inception_features_val'], [-1, 2048]), train_dict['labels'])\n",
    "test_dict = np.load('/srv/scratch/pangwei/influence_data/%s_features_test.npz' % model_string)\n",
    "test = DataSet(np.reshape(test_dict['inception_features_val'], [-1, 2048]), test_dict['labels'])\n",
    "validation = None\n",
    "\n",
    "data_sets = base.Datasets(train=train, validation=validation, test=test)\n",
    "\n",
    "modify_type = 'replace'\n",
    "assert(all(image_data_sets.train.labels == data_sets.train.labels))\n",
    "assert(all(image_data_sets.test.labels == data_sets.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 2048\n",
    "weight_decay = 0.001\n",
    "batch_size = 900\n",
    "initial_learning_rate = 0.001 \n",
    "keep_probs = None\n",
    "decay_epochs = [1000, 10000]\n",
    "max_lbfgs_iter = 1000\n",
    "num_classes = 2\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "model = BinaryLogisticRegressionWithLBFGS(\n",
    "    input_dim=input_dim,\n",
    "    weight_decay=weight_decay,\n",
    "    max_lbfgs_iter=max_lbfgs_iter,\n",
    "    num_classes=num_classes, \n",
    "    batch_size=batch_size,\n",
    "    data_sets=data_sets,\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    keep_probs=keep_probs,\n",
    "    decay_epochs=decay_epochs,\n",
    "    mini_batch=False,\n",
    "    train_dir='data',\n",
    "    log_dir='log',\n",
    "    model_name='%s_inception_onlytop_poisoned' % model_name)\n",
    "\n",
    "model.train()\n",
    "\n",
    "# Y_test = model.data_sets.test.labels\n",
    "attacked_Y_pred = model.sess.run(model.preds, feed_dict=model.all_test_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_idx)\n",
    "print(Y_pred[test_idx])\n",
    "print(attacked_Y_pred[test_idx])\n",
    "plt.imshow((np.reshape(image_data_sets.test.x[test_idx, :], [299, 299, 3]) + 1) / 2, interpolation='none')  \n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_correct = np.zeros([len(Y_test)])\n",
    "for idx, label in enumerate(Y_test):\n",
    "    Y_pred_correct[idx] = Y_pred[idx, int(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisoned_Y_pred_correct = Y_pred_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_Y_pred_correct = Y_pred_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(orig_Y_pred_correct, kde=False)\n",
    "sns.distplot(poisoned_Y_pred_correct, kde=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(orig_Y_pred_correct - Y_pred_correct, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(orig_Y_pred_correct - poisoned_Y_pred_correct, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('True: %s' % Y_test[test_idx])\n",
    "print('Predicted: %s' % Y_pred[test_idx])\n",
    "\n",
    "test_image = reverse_preprocess(np.copy(image_data_sets.test.x[test_idx, :]))\n",
    "test_label = image_data_sets.test.labels[test_idx]\n",
    "plot_flat_colorimage(test_image, test_label, side=299)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pictures of animals and their predictions (without poisoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = 1\n",
    "print('True: %s' % Y_test[test_idx])\n",
    "print('Predicted: %s' % Y_pred[test_idx, :])\n",
    "\n",
    "test_image = reverse_preprocess(np.copy(image_data_sets.test.x[test_idx, :]))\n",
    "test_label = image_data_sets.test.labels[test_idx]\n",
    "plot_flat_colorimage(test_image, test_label, side=299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = 15\n",
    "print('True: %s' % Y_test[test_idx])\n",
    "print('Predicted: %s' % Y_pred[test_idx])\n",
    "log_loss = -np.log(Y_test[test_idx] * Y_pred[test_idx] + (1 - Y_test[test_idx]) * (1 - Y_pred[test_idx]))\n",
    "print('Log loss: %s' % log_loss)\n",
    "\n",
    "test_image = reverse_preprocess(np.copy(image_data_sets.test.x[test_idx, :]))\n",
    "test_label = image_data_sets.test.labels[test_idx]\n",
    "plot_flat_colorimage(test_image, test_label, side=299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = 33\n",
    "print('True: %s' % Y_test[test_idx])\n",
    "print('Predicted: %s' % Y_pred[test_idx])\n",
    "log_loss = -np.log(Y_test[test_idx] * Y_pred[test_idx] + (1 - Y_test[test_idx]) * (1 - Y_pred[test_idx]))\n",
    "print('Log loss: %s' % log_loss)\n",
    "\n",
    "test_image = reverse_preprocess(np.copy(image_data_sets.test.x[test_idx, :]))\n",
    "test_label = image_data_sets.test.labels[test_idx]\n",
    "plot_flat_colorimage(test_image, test_label, side=299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = 484\n",
    "np.sort(Y_pred)[sort_idx]\n",
    "test_idx = np.argsort(Y_pred)[sort_idx]\n",
    "print(test_idx)\n",
    "print('True: %s' % Y_test[test_idx])\n",
    "print('Predicted: %s' % Y_pred[test_idx])\n",
    "log_loss = -np.log(Y_test[test_idx] * Y_pred[test_idx] + (1 - Y_test[test_idx]) * (1 - Y_pred[test_idx]))\n",
    "print('Log loss: %s' % log_loss)\n",
    "\n",
    "test_image = reverse_preprocess(np.copy(image_data_sets.test.x[test_idx, :]))\n",
    "test_label = image_data_sets.test.labels[test_idx]\n",
    "plot_flat_colorimage(test_image, test_label, side=299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = 45\n",
    "print('True: %s' % Y_test[test_idx])\n",
    "print('Predicted: %s' % Y_pred[test_idx])\n",
    "\n",
    "test_image = reverse_preprocess(np.copy(image_data_sets.test.x[test_idx, :]))\n",
    "test_label = image_data_sets.test.labels[test_idx]\n",
    "plot_flat_colorimage(test_image, test_label, side=299)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How different are the poisoned examples vs. normal variation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(image_data_sets.train.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average l2 distance of each training example to their \n",
    "# cluster center\n",
    "dim = image_data_sets.train.x.shape[1]\n",
    "centers = np.zeros([2, dim])\n",
    "avg_dist = np.zeros([2])\n",
    "for label in [0, 1]:\n",
    "    label_indices = (image_data_sets.train.labels == label)\n",
    "    centers[label, :] = np.mean(image_data_sets.train.x[label_indices, :], axis=0)\n",
    "    dists = image_data_sets.train.x[label_indices, :] - centers[label]\n",
    "    avg_dist[label] = np.mean(np.linalg.norm(dists, axis=1))\n",
    "\n",
    "avg_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute l2 distance of a perturbed example to the original example\n",
    "# Each pixel is modified by (2.0 / 255)\n",
    "perturbed_distance = np.sqrt(dim * 2.0 / 255)\n",
    "perturbed_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature space\n",
    "normal_train_dict = np.load('data/%s_features_train.npz' % model_string)\n",
    "X = normal_train_dict['inception_features_val']\n",
    "Y = normal_train_dict['labels']\n",
    "\n",
    "dim = X.shape[1]\n",
    "centers = np.zeros([2, dim])\n",
    "avg_dist = np.zeros([2])\n",
    "for label in [0, 1]:\n",
    "    label_indices = (Y == label)\n",
    "    centers[label, :] = np.mean(X[label_indices, :], axis=0)\n",
    "    dists = X[label_indices, :] - centers[label]\n",
    "    norms = np.linalg.norm(dists, axis=1)\n",
    "    avg_dist[label] = np.mean(np.linalg.norm(dists, axis=1))\n",
    "    sns.distplot(norms)\n",
    "\n",
    "avg_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_train_dict = np.load('data/%s_features_train.npz' % model_string)\n",
    "X = normal_train_dict['inception_features_val']\n",
    "Y = normal_train_dict['labels']\n",
    "\n",
    "poisoned_train_dict = np.load('data/normal_dog_2000_1000_inception_inception_features_poisoned_train_influence_poison-maxgrad-linf-replace-0.05_testidx_825.npz')\n",
    "X_poison = poisoned_train_dict['inception_features_val']\n",
    "Y_poison = poisoned_train_dict['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(Y == Y_poison)\n",
    "modified_idx = np.where(~np.all(X == X_poison, axis=1))[0]\n",
    "dists = X_poison[modified_idx, :] - X[modified_idx, :]\n",
    "np.mean(np.linalg.norm(dists, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in [0, 1]:\n",
    "    label_indices = (Y_poison == label)\n",
    "    centers[label, :] = np.mean(X_poison[label_indices, :], axis=0)        \n",
    "    dists = X_poison[label_indices, :] - centers[label]\n",
    "    norms = np.linalg.norm(dists, axis=1)\n",
    "    avg_dist[label] = np.mean(np.linalg.norm(dists, axis=1))\n",
    "\n",
    "X_unmodified = X_poison[~modified_idx, :]\n",
    "Y_unmodified = Y_poison[~modified_idx]\n",
    "for label in [0, 1]:\n",
    "    label_indices = (Y_unmodified == label)\n",
    "    dists = X_unmodified[label_indices, :] - centers[label]\n",
    "    avg_dist[label] = np.mean(np.linalg.norm(dists, axis=1))\n",
    "    norms = np.linalg.norm(dists, axis=1)\n",
    "    sns.distplot(norms)\n",
    "\n",
    "X_modified = X_poison[modified_idx, :]\n",
    "Y_modified = Y_poison[modified_idx]\n",
    "for label in [0, 1]:\n",
    "    label_indices = (Y_modified == label)\n",
    "    dists = X_modified[label_indices, :] - centers[label]\n",
    "    avg_dist[label] = np.mean(np.linalg.norm(dists, axis=1))\n",
    "    norms = np.linalg.norm(dists, axis=1)\n",
    "    sns.distplot(norms)\n",
    "avg_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(centers[0, :] - centers[1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize poisoned training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.load('data/skewed_dog_inception_poisoned_data_sets_testidx_403.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisoned_train = f[0]\n",
    "validation = f[1]\n",
    "test = f[2]\n",
    "poisoned_data_sets = poisoned_data_sets = base.Datasets(train=poisoned_train, validation=validation, test=test)\n",
    "\n",
    "assert np.all(poisoned_data_sets.test.x == image_data_sets.test.x)\n",
    "assert all(poisoned_data_sets.test.labels == image_data_sets.test.labels)\n",
    "assert all(poisoned_data_sets.train.labels == image_data_sets.train.labels)\n",
    "assert (np.max(np.abs(poisoned_data_sets.train.x - image_data_sets.train.x)) * 255 / 2) <= 1.0001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(poisoned_data_sets.train.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make sure that the poisoned data sets are at most 1 different from the orig data sets in each pixel\n",
    "np.max(np.abs(poisoned_data_sets.train.x - image_data_sets.train.x)) * 255 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = 1225\n",
    "\n",
    "orig_train_image = reverse_preprocess(np.copy(image_data_sets.train.x[train_idx, :]))\n",
    "orig_train_label = image_data_sets.train.labels[train_idx]\n",
    "plot_flat_colorimage(orig_train_image, orig_train_label, side=299)\n",
    "\n",
    "poisoned_train_image = reverse_preprocess(np.copy(poisoned_data_sets.train.x[train_idx, :]))\n",
    "poisoned_train_label = poisoned_data_sets.train.labels[train_idx]\n",
    "plot_flat_colorimage(poisoned_train_image, poisoned_train_label, side=299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = poisoned_train_image - orig_train_image\n",
    "\n",
    "diff < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisoned_train_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = poisoned_train_image - orig_train_image\n",
    "diff[diff < 0] = 0\n",
    "reshaped_diff = np.reshape(diff, [299, 299, 3])\n",
    "# print(reshaped_diff[:10, :10, :])\n",
    "plot_flat_colorgrad(diff * 10, side=299)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The change in model behavior could be because of a change in the logistic regression weights, or a change in the Inception features generated.\n",
    "\n",
    "Seems like both change...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How different are the learned weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train normal model\n",
    "train_dict = np.load('data/skewed_dog_inception_morereg_inception_features_train.npz')\n",
    "train = DataSet(np.reshape(train_dict['inception_features_val'], [-1, 2048]), train_dict['labels'])\n",
    "test_dict = np.load('data/skewed_dog_inception_morereg_inception_features_test.npz')\n",
    "test = DataSet(np.reshape(test_dict['inception_features_val'], [-1, 2048]), test_dict['labels'])\n",
    "validation = None\n",
    "data_sets = base.Datasets(train=train, validation=validation, test=test)\n",
    "assert(all(image_data_sets.train.labels == data_sets.train.labels))\n",
    "assert(all(image_data_sets.test.labels == data_sets.test.labels))\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "model = BinaryLogisticRegressionWithLBFGS(\n",
    "    input_dim=input_dim,\n",
    "    weight_decay=weight_decay,\n",
    "    max_lbfgs_iter=max_lbfgs_iter,\n",
    "    num_classes=num_classes, \n",
    "    batch_size=batch_size,\n",
    "    data_sets=data_sets,\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    keep_probs=keep_probs,\n",
    "    decay_epochs=decay_epochs,\n",
    "    mini_batch=False,\n",
    "    train_dir='data',\n",
    "    log_dir='log',\n",
    "    model_name='skewed_dog_inception_onlytop_poisoned')\n",
    "\n",
    "model.train()\n",
    "normal_weights = model.sess.run(model.params)[0]\n",
    "\n",
    "# Train poisoned model\n",
    "test_idx = 403\n",
    "\n",
    "train_dict = np.load('data/skewed_dog_inception_inception_features_poisoned_train_influence_testidx_%s.npz' % test_idx) \n",
    "train = DataSet(np.reshape(train_dict['inception_features_val'], [-1, 2048]), train_dict['labels'])\n",
    "test_dict = np.load('data/skewed_dog_inception_morereg_inception_features_test.npz')\n",
    "test = DataSet(np.reshape(test_dict['inception_features_val'], [-1, 2048]), test_dict['labels'])\n",
    "validation = None\n",
    "data_sets = base.Datasets(train=train, validation=validation, test=test)\n",
    "assert(all(image_data_sets.train.labels == data_sets.train.labels))\n",
    "assert(all(image_data_sets.test.labels == data_sets.test.labels))\n",
    "tf.reset_default_graph()\n",
    "\n",
    "model = BinaryLogisticRegressionWithLBFGS(\n",
    "    input_dim=input_dim,\n",
    "    weight_decay=weight_decay,\n",
    "    max_lbfgs_iter=max_lbfgs_iter,\n",
    "    num_classes=num_classes, \n",
    "    batch_size=batch_size,\n",
    "    data_sets=data_sets,\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    keep_probs=keep_probs,\n",
    "    decay_epochs=decay_epochs,\n",
    "    mini_batch=False,\n",
    "    train_dir='data',\n",
    "    log_dir='log',\n",
    "    model_name='skewed_dog_inception_onlytop_poisoned')\n",
    "\n",
    "model.train()\n",
    "poisoned_weights = model.sess.run(model.params)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(normal_weights, poisoned_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisoned_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How different are the Inception features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal\n",
    "normal_train_dict = np.load('data/skewed_dog_inception_morereg_inception_features_train.npz')\n",
    "\n",
    "# Poisoned\n",
    "test_idx = 10\n",
    "poisoned_train_dict = np.load('data/skewed_dog_inception_inception_features_poisoned_train_influence_testidx_%s.npz' % test_idx) \n",
    "# poisoned_train_dict = np.load('data/skewed_dog_inception_inception_features_poisoned_train_random_testidx_None.npz')\n",
    "# poisoned_train_dict = np.load('data/skewed_dog_inception_inception_features_poisoned_train_traingrad_testidx_None.npz')\n",
    "# poisoned_train_dict = np.load('data/skewed_dog_inception_inception_features_poisoned_train_mirror_testidx_%s.npz' % test_idx)\n",
    "\n",
    "# poisoned_train_dict = np.load('data/skewed_dog_inception_inception_features_poisoned_train_testidx_None.npz')\n",
    "\n",
    "X_train_normal = normal_train_dict['inception_features_val']\n",
    "X_train_poisoned = poisoned_train_dict['inception_features_val']\n",
    "\n",
    "Y_train_normal = normal_train_dict['labels']\n",
    "Y_train_poisoned = poisoned_train_dict['labels']\n",
    "assert(all(Y_train_normal == Y_train_poisoned))\n",
    "# np.reshape(train_dict['inception_features_val'], [-1, 2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = X_train_normal - X_train_poisoned\n",
    "diff_norm = np.linalg.norm(diff, axis=1)\n",
    "normal_norm = np.linalg.norm(X_train_normal, axis=1)\n",
    "poisoned_norm = np.linalg.norm(X_train_poisoned, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(normal_norm, poisoned_norm)\n",
    "plt.xlim(15, 55)\n",
    "plt.ylim(15, 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(diff_norm)\n",
    "sns.distplot(normal_norm)\n",
    "sns.distplot(poisoned_norm)\n",
    "\n",
    "# Blue: Differences\n",
    "# Green: Original\n",
    "# Red: Poisoned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
